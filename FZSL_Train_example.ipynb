{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the packages\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "import os\n",
    "from lightning.pytorch import Trainer, seed_everything #https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping #3\n",
    "from lightning.pytorch.loggers import TensorBoardLogger #3\n",
    "from maldi_zsl_edit.data import MALDITOFDataModule #1\n",
    "from maldi_zsl_edit.models import ZSLClassifier #2\n",
    "import random\n",
    "from torch import manual_seed as torch_manual_seed\n",
    "from numpy.random import seed as np_random_seed\n",
    "from torch.cuda import is_available as torch_cuda_is_available\n",
    "from torch.cuda import manual_seed as torch_cuda_manual_seed\n",
    "from torch.cuda import manual_seed_all as torch_cuda_manual_seed_all\n",
    "#import h5py\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 4\n"
     ]
    }
   ],
   "source": [
    "#for reproduce the run\n",
    "def set_seed(seed):\n",
    "    seed_everything(seed, workers=True)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np_random_seed(seed)\n",
    "    torch_manual_seed(seed)\n",
    "    if torch_cuda_is_available():\n",
    "        torch_cuda_manual_seed(seed)\n",
    "        torch_cuda_manual_seed_all(seed)\n",
    "set_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data set\n",
    "data_path = \"Data/zsl_SINAwasabi.h5t\"\n",
    "dm = MALDITOFDataModule( #Personalized lightning data modules\n",
    "    data_path, #The old has problems on split\n",
    "    zsl_mode = True, # False: multi-class CLF, True: ZSL\n",
    "    split_index = 1, # 0 for not general eva 1 for general eva, 2 for general with no seen classes at validation\n",
    "    batch_size = 512, # important hyperparameter\n",
    "    n_workers = 2, # you can leave this always if you are not CPU limited\n",
    "    in_memory = True, # you can leave this always if memory is no problems\n",
    "    general = True # False: Regular ZSL (only val species), True:General ZSL (val+train species)\n",
    "    )\n",
    "dm.setup(None)\n",
    "\n",
    "#Check?\n",
    "#if True:\n",
    "#    batch = next(iter(dm.train_dataloader()))\n",
    "#    print(batch.keys())\n",
    "#    print(batch['seq_ohe'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now there should be a batch instance [\"seq_ohe]\", replace the batch[\"seq\"] with it in the models file\n",
    "n_species = 623 #batch['strain'].shape[0] #Number the seq considered for the train, #The batch should be 623 (463 of training and 160 of val, the rest 165 are on test)\n",
    "t_species = 463\n",
    "model = ZSLClassifier(\n",
    "    embed_dim=1024, #520\n",
    "    cnn_kwargs= { #specify the parameters to buld the CNN () #[The limit is 64,128]\n",
    "        'conv_sizes' : [64,128], #[32, 64, 128] Out chanels of the convolutions #On the nlp mode the first is an embeding dimension\n",
    "        'hidden_sizes' : [0], #MLP: [512, 256]. If [0] then goes directly from conv to embeding layer\n",
    "        'blocks_per_stage' : 2, #How many residual blocks are applied before the pooling\n",
    "        'kernel_size' : 7,\n",
    "        'dropout' : 0.2,\n",
    "        'mode': \"max\", #max or mean\n",
    "    },\n",
    "    n_classes = n_species,\n",
    "    t_classes = t_species,\n",
    "    lr=1e-3, # important to tune\n",
    "    weight_decay=0, # this you can keep constant\n",
    "    lr_decay_factor=1.00, # this you can keep constant\n",
    "    warmup_steps=250, # this you can keep constant\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZSLClassifier(\n",
       "  (spectrum_embedder): MLPEmbedding(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=6000, out_features=512, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Dropout(p=0.2, inplace=False)\n",
       "      (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (8): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (9): GELU(approximate='none')\n",
       "      (10): Dropout(p=0.2, inplace=False)\n",
       "      (11): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (12): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (13): GELU(approximate='none')\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (16): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (seq_embedder): CNNEmbedding(\n",
       "    (net): Sequential(\n",
       "      (0): Conv1d(6, 64, kernel_size=(3,), stride=(1,))\n",
       "      (1): ResidualBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=same)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Permute()\n",
       "          (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (5): Permute()\n",
       "        )\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=same)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Permute()\n",
       "          (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (5): Permute()\n",
       "        )\n",
       "      )\n",
       "      (3): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
       "      (4): ResidualBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=same)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Permute()\n",
       "          (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (5): Permute()\n",
       "        )\n",
       "      )\n",
       "      (5): ResidualBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=same)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Permute()\n",
       "          (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (5): Permute()\n",
       "        )\n",
       "      )\n",
       "      (6): GlobalPool()\n",
       "      (7): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (accuracy): MulticlassAccuracy()\n",
       "  (accuracy2): MulticlassAccuracy()\n",
       "  (top5_accuracy): MulticlassAccuracy()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#Save and monitor training with tensor board\n",
    "from datetime import datetime\n",
    "timenow = datetime.now()\n",
    "strtime = timenow.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "val_ckpt = ModelCheckpoint(monitor=\"val_acc\", mode=\"max\")\n",
    "callbacks = [val_ckpt, EarlyStopping(monitor=\"val_acc\", patience=25, mode=\"max\")]\n",
    "logger = TensorBoardLogger(\"logs\", name=\"zsl_train\", version=strtime) # Ctrl+Shift+P # Main folder where the training is saved and the name for the training\n",
    "\n",
    "#Training specification\n",
    "trainer = Trainer(\n",
    "    min_epochs= 50,\n",
    "    max_epochs = 125, \n",
    "    accelerator='gpu', \n",
    "    strategy='auto',\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    devices=[0]) #You can define epochs and training devices (look on documentation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from check point\n",
    "sure = False\n",
    "if sure:\n",
    "    from torch import load as torch_load\n",
    "    model = torch_load('Models/Model_1')\n",
    "    checkpath = 'logs/2024-08-07_13-29-32/checkpoints/epoch=77-step=2340.ckpt'\n",
    "    checkpoint = torch_load(checkpath)\n",
    "    \n",
    "    for name, param in checkpoint['state_dict'].items():\n",
    "        print(f\"Key: {name}, Shape: {param.shape}\")\n",
    "    for name, param in model.state_dict().items():\n",
    "        print(f\"Key: {name}, Shape: {param.shape}\")\n",
    "    model.state_dict().keys() == checkpoint['state_dict'].keys()\n",
    "\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    trainer = Trainer(resume_from_checkpoint=checkpath)#To resume the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name              | Type               | Params\n",
      "---------------------------------------------------------\n",
      "0 | spectrum_embedder | MLPEmbedding       | 5.6 M \n",
      "1 | seq_embedder      | CNNEmbedding       | 437 K \n",
      "2 | accuracy          | MulticlassAccuracy | 0     \n",
      "3 | accuracy2         | MulticlassAccuracy | 0     \n",
      "4 | top5_accuracy     | MulticlassAccuracy | 0     \n",
      "---------------------------------------------------------\n",
      "6.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.0 M     Total params\n",
      "24.038    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/Thesis/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  3.10it/s]\n",
      "Epoch 0 - Train loss: NA, Train accu: 0.0\n",
      "Epoch 0 - Val loss: 13.60734748840332, Val accu: 0.0\n",
      "\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/Thesis/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/jorge/anaconda3/envs/Thesis/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 30/30 [00:15<00:00,  1.96it/s, v_num=1-06]\n",
      "Epoch 0 - Train loss: 17.094280242919922, Train accu: 0.0020833334419876337\n",
      "Epoch 0 - Val loss: 6.6367411613464355, Val accu: 0.0\n",
      "\n",
      "Epoch 1: 100%|██████████| 30/30 [00:15<00:00,  1.94it/s, v_num=1-06]\n",
      "Epoch 1 - Train loss: 7.635072231292725, Train accu: 0.00264359381981194\n",
      "Epoch 1 - Val loss: 6.4396467208862305, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 2: 100%|██████████| 30/30 [00:15<00:00,  1.92it/s, v_num=1-06]\n",
      "Epoch 2 - Train loss: 6.661075115203857, Train accu: 0.002057656180113554\n",
      "Epoch 2 - Val loss: 6.437726974487305, Val accu: 0.0029296877328306437\n",
      "\n",
      "Epoch 3: 100%|██████████| 30/30 [00:16<00:00,  1.87it/s, v_num=1-06]\n",
      "Epoch 3 - Train loss: 6.491706371307373, Train accu: 0.0023831771686673164\n",
      "Epoch 3 - Val loss: 6.445499897003174, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 4: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 4 - Train loss: 6.421058177947998, Train accu: 0.002298359526321292\n",
      "Epoch 4 - Val loss: 6.43692684173584, Val accu: 0.00041852681897580624\n",
      "\n",
      "Epoch 5: 100%|██████████| 30/30 [00:16<00:00,  1.82it/s, v_num=1-06]\n",
      "Epoch 5 - Train loss: 6.3525261878967285, Train accu: 0.0017775261076167226\n",
      "Epoch 5 - Val loss: 6.432461261749268, Val accu: 0.00041852681897580624\n",
      "\n",
      "Epoch 6: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 6 - Train loss: 6.320337295532227, Train accu: 0.0027738020289689302\n",
      "Epoch 6 - Val loss: 6.45391321182251, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 7: 100%|██████████| 30/30 [00:16<00:00,  1.83it/s, v_num=1-06]\n",
      "Epoch 7 - Train loss: 6.305057048797607, Train accu: 0.001757812569849193\n",
      "Epoch 7 - Val loss: 6.46825647354126, Val accu: 0.0\n",
      "\n",
      "Epoch 8: 100%|██████████| 30/30 [00:16<00:00,  1.82it/s, v_num=1-06]\n",
      "Epoch 8 - Train loss: 6.2884745597839355, Train accu: 0.002103046979755163\n",
      "Epoch 8 - Val loss: 6.454233646392822, Val accu: 0.015206473879516125\n",
      "\n",
      "Epoch 9: 100%|██████████| 30/30 [00:16<00:00,  1.86it/s, v_num=1-06]\n",
      "Epoch 9 - Train loss: 6.256296634674072, Train accu: 0.0022786459885537624\n",
      "Epoch 9 - Val loss: 6.421449184417725, Val accu: 0.0\n",
      "\n",
      "Epoch 10: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 10 - Train loss: 6.237093925476074, Train accu: 0.002539062639698386\n",
      "Epoch 10 - Val loss: 6.434109210968018, Val accu: 0.00013950893480796367\n",
      "\n",
      "Epoch 11: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 11 - Train loss: 6.2313737869262695, Train accu: 0.0026889843866229057\n",
      "Epoch 11 - Val loss: 6.45005989074707, Val accu: 0.00013950893480796367\n",
      "\n",
      "Epoch 12: 100%|██████████| 30/30 [00:16<00:00,  1.82it/s, v_num=1-06]\n",
      "Epoch 12 - Train loss: 6.217547416687012, Train accu: 0.0023437500931322575\n",
      "Epoch 12 - Val loss: 6.436601638793945, Val accu: 0.0\n",
      "\n",
      "Epoch 13: 100%|██████████| 30/30 [00:16<00:00,  1.87it/s, v_num=1-06]\n",
      "Epoch 13 - Train loss: 6.214864253997803, Train accu: 0.002493671840056777\n",
      "Epoch 13 - Val loss: 6.438820838928223, Val accu: 0.00041852681897580624\n",
      "\n",
      "Epoch 14: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 14 - Train loss: 6.209150314331055, Train accu: 0.001692708465270698\n",
      "Epoch 14 - Val loss: 6.432443618774414, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 15: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 15 - Train loss: 6.201981067657471, Train accu: 0.0022332551889121532\n",
      "Epoch 15 - Val loss: 6.439545631408691, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 16: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 16 - Train loss: 6.195747375488281, Train accu: 0.0025587761774659157\n",
      "Epoch 16 - Val loss: 6.426122665405273, Val accu: 0.00013950893480796367\n",
      "\n",
      "Epoch 17: 100%|██████████| 30/30 [00:16<00:00,  1.86it/s, v_num=1-06]\n",
      "Epoch 17 - Train loss: 6.1905083656311035, Train accu: 0.001992552075535059\n",
      "Epoch 17 - Val loss: 6.4213547706604, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 18: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 18 - Train loss: 6.1875691413879395, Train accu: 0.002037942875176668\n",
      "Epoch 18 - Val loss: 6.439870357513428, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 19: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 19 - Train loss: 6.181950569152832, Train accu: 0.0021484375465661287\n",
      "Epoch 19 - Val loss: 6.431152820587158, Val accu: 0.0\n",
      "\n",
      "Epoch 20: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 20 - Train loss: 6.1874589920043945, Train accu: 0.001953125\n",
      "Epoch 20 - Val loss: 6.441610336303711, Val accu: 0.0005580357392318547\n",
      "\n",
      "Epoch 21: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 21 - Train loss: 6.176702499389648, Train accu: 0.0024088541977107525\n",
      "Epoch 21 - Val loss: 6.44400691986084, Val accu: 0.00013950893480796367\n",
      "\n",
      "Epoch 22: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 22 - Train loss: 6.172677516937256, Train accu: 0.0025587761774659157\n",
      "Epoch 22 - Val loss: 6.439798831939697, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 23: 100%|██████████| 30/30 [00:16<00:00,  1.82it/s, v_num=1-06]\n",
      "Epoch 23 - Train loss: 6.173458099365234, Train accu: 0.0020182293374091387\n",
      "Epoch 23 - Val loss: 6.435052871704102, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 24: 100%|██████████| 30/30 [00:16<00:00,  1.82it/s, v_num=1-06]\n",
      "Epoch 24 - Train loss: 6.174691677093506, Train accu: 0.0021484375465661287\n",
      "Epoch 24 - Val loss: 6.432109355926514, Val accu: 0.0078125\n",
      "\n",
      "Epoch 25: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 25 - Train loss: 6.168776035308838, Train accu: 0.002363463630899787\n",
      "Epoch 25 - Val loss: 6.444794178009033, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 26: 100%|██████████| 30/30 [00:16<00:00,  1.86it/s, v_num=1-06]\n",
      "Epoch 26 - Train loss: 6.165225028991699, Train accu: 0.001888020895421505\n",
      "Epoch 26 - Val loss: 6.444268703460693, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 27: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 27 - Train loss: 6.164349555969238, Train accu: 0.0023437500931322575\n",
      "Epoch 27 - Val loss: 6.437925338745117, Val accu: 0.0\n",
      "\n",
      "Epoch 28: 100%|██████████| 30/30 [00:16<00:00,  1.87it/s, v_num=1-06]\n",
      "Epoch 28 - Train loss: 6.165041446685791, Train accu: 0.0022135418839752674\n",
      "Epoch 28 - Val loss: 6.435556411743164, Val accu: 0.0\n",
      "\n",
      "Epoch 29: 100%|██████████| 30/30 [00:16<00:00,  1.82it/s, v_num=1-06]\n",
      "Epoch 29 - Train loss: 6.1603593826293945, Train accu: 0.002402890706434846\n",
      "Epoch 29 - Val loss: 6.447022914886475, Val accu: 0.00013950893480796367\n",
      "\n",
      "Epoch 30: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 30 - Train loss: 6.160724639892578, Train accu: 0.0022726822644472122\n",
      "Epoch 30 - Val loss: 6.437308311462402, Val accu: 0.00823102705180645\n",
      "\n",
      "Epoch 31: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 31 - Train loss: 6.158339023590088, Train accu: 0.002363463630899787\n",
      "Epoch 31 - Val loss: 6.4396257400512695, Val accu: 0.00013950893480796367\n",
      "\n",
      "Epoch 32: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 32 - Train loss: 6.158991813659668, Train accu: 0.00182291679084301\n",
      "Epoch 32 - Val loss: 6.430419445037842, Val accu: 0.0\n",
      "\n",
      "Epoch 33: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 33 - Train loss: 6.1559157371521, Train accu: 0.0025133853778243065\n",
      "Epoch 33 - Val loss: 6.439082622528076, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 34:   0%|          | 0/30 [00:00<?, ?it/s, v_num=1-06]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but the required `min_epochs=50` or `min_steps=None` has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 30/30 [00:16<00:00,  1.86it/s, v_num=1-06]\n",
      "Epoch 34 - Train loss: 6.153400421142578, Train accu: 0.001992552075535059\n",
      "Epoch 34 - Val loss: 6.435069561004639, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 35: 100%|██████████| 30/30 [00:16<00:00,  1.82it/s, v_num=1-06]\n",
      "Epoch 35 - Train loss: 6.15416955947876, Train accu: 0.0022135418839752674\n",
      "Epoch 35 - Val loss: 6.432463645935059, Val accu: 0.0005580357392318547\n",
      "\n",
      "Epoch 36: 100%|██████████| 30/30 [00:16<00:00,  1.83it/s, v_num=1-06]\n",
      "Epoch 36 - Train loss: 6.150712013244629, Train accu: 0.001927447970956564\n",
      "Epoch 36 - Val loss: 6.431375026702881, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 37: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 37 - Train loss: 6.1511077880859375, Train accu: 0.0022135418839752674\n",
      "Epoch 37 - Val loss: 6.431115627288818, Val accu: 0.00041852681897580624\n",
      "\n",
      "Epoch 38: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 38 - Train loss: 6.148756504058838, Train accu: 0.002493671840056777\n",
      "Epoch 38 - Val loss: 6.437811851501465, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 39: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 39 - Train loss: 6.151352405548096, Train accu: 0.0016276042442768812\n",
      "Epoch 39 - Val loss: 6.4284234046936035, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 40: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 40 - Train loss: 6.14825963973999, Train accu: 0.0016473177820444107\n",
      "Epoch 40 - Val loss: 6.434908866882324, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 41: 100%|██████████| 30/30 [00:16<00:00,  1.86it/s, v_num=1-06]\n",
      "Epoch 41 - Train loss: 6.1466288566589355, Train accu: 0.002473958535119891\n",
      "Epoch 41 - Val loss: 6.426129341125488, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 42: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 42 - Train loss: 6.149783134460449, Train accu: 0.001953125\n",
      "Epoch 42 - Val loss: 6.424900531768799, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 43: 100%|██████████| 30/30 [00:16<00:00,  1.82it/s, v_num=1-06]\n",
      "Epoch 43 - Train loss: 6.147510051727295, Train accu: 0.0021681510843336582\n",
      "Epoch 43 - Val loss: 6.426214694976807, Val accu: 0.0\n",
      "\n",
      "Epoch 44: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s, v_num=1-06]\n",
      "Epoch 44 - Train loss: 6.1462721824646, Train accu: 0.00266927108168602\n",
      "Epoch 44 - Val loss: 6.4297614097595215, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 45: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 45 - Train loss: 6.14593505859375, Train accu: 0.0023437500931322575\n",
      "Epoch 45 - Val loss: 6.428348064422607, Val accu: 0.0\n",
      "\n",
      "Epoch 46: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s, v_num=1-06]\n",
      "Epoch 46 - Train loss: 6.145288944244385, Train accu: 0.0023377863690257072\n",
      "Epoch 46 - Val loss: 6.4335761070251465, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 47: 100%|██████████| 30/30 [00:16<00:00,  1.83it/s, v_num=1-06]\n",
      "Epoch 47 - Train loss: 6.143209934234619, Train accu: 0.0032295312266796827\n",
      "Epoch 47 - Val loss: 6.434323310852051, Val accu: 0.004464285913854837\n",
      "\n",
      "Epoch 48: 100%|██████████| 30/30 [00:16<00:00,  1.83it/s, v_num=1-06]\n",
      "Epoch 48 - Train loss: 6.140126705169678, Train accu: 0.001992552075535059\n",
      "Epoch 48 - Val loss: 6.424978733062744, Val accu: 0.0115792416036129\n",
      "\n",
      "Epoch 49: 100%|██████████| 30/30 [00:16<00:00,  1.83it/s, v_num=1-06]\n",
      "Epoch 49 - Train loss: 6.12411642074585, Train accu: 0.002103046979755163\n",
      "Epoch 49 - Val loss: 6.413569927215576, Val accu: 0.00027901786961592734\n",
      "\n",
      "Epoch 49: 100%|██████████| 30/30 [00:21<00:00,  1.37it/s, v_num=1-06]\n"
     ]
    }
   ],
   "source": [
    "#Start training\n",
    "trainer.fit(model, dm.train_dataloader(), dm.val_dataloader()) #Important: normally you can use only dm, but here we specify as the dim of a are different for train and val \n",
    "#Note: The model object specify what is considered an input values and what is considered an input/output value during the training on the training step method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as ZSLmodel2024-08-19_20-01-06.pth\n"
     ]
    }
   ],
   "source": [
    "#timenow = datetime.now()\n",
    "#traintime = timenow.strftime(\"%Y-%m-%d_%H-%M-%S\") - strtime\n",
    "#print(f\"The model lasted {traintime} to train\")\n",
    "\n",
    "#Save the model also at the end of the training\n",
    "sure = True\n",
    "if sure:\n",
    "    from torch import save as torch_save\n",
    "    torch_save(model, f'Models/ZSLmodel{strtime}.pth')\n",
    "    print(f\"Saved as ZSLmodel{strtime}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 hours and 17 minutes\n"
     ]
    }
   ],
   "source": [
    "end = datetime.now() - timenow\n",
    "total_seconds = end.total_seconds()\n",
    "hours = total_seconds // 3600\n",
    "minutes = (total_seconds % 3600) // 60\n",
    "\n",
    "print(f\"{int(hours)} hours and {int(minutes)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import load as torch_load\n",
    "#model = torch_load('../SavedModels/ZSLmodel2024-08-18_17-27-39.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Getting predictions ---\n",
      "Working with test set\n",
      "\n",
      "For Family there are 77 different labels\n",
      "For Genus there are 154 different labels\n",
      "For Species there are 568 different labels\n",
      "For Strain there are 628 different labels\n",
      "\n",
      "--- Multi level evaluation general ---\n",
      "\n",
      "--- Calculating Accuracy ---\n",
      "For the level Family the accu score is: 0.19635498523712158\n",
      "For the level Genus the accu score is: 0.05118858814239502\n",
      "For the level Species the accu score is: 0.006022186949849129\n",
      "For the level Strain the accu score is: 0.005705229938030243\n",
      "\n",
      "--- Calculating F1 scores ---\n",
      "For the level Family the F1 score is: 0.026128826662898064\n",
      "For the level Genus the F1 score is: 0.008865450508892536\n",
      "For the level Species the F1 score is: 0.0009803102584555745\n",
      "For the level Strain the F1 score is: 0.0008283915231004357\n",
      "\n",
      "--- Multi level evaluation test_geni ---\n",
      "\n",
      "--- Calculating Accuracy ---\n",
      "For the level Family the accu score is: 0.18151001632213593\n",
      "For the level Genus the accu score is: 0.051463790237903595\n",
      "For the level Species the accu score is: 0.009244992397725582\n",
      "For the level Strain the accu score is: 0.008936826139688492\n",
      "\n",
      "--- Calculating F1 scores ---\n",
      "For the level Family the F1 score is: 0.028194142505526543\n",
      "For the level Genus the F1 score is: 0.010462125763297081\n",
      "For the level Species the F1 score is: 0.001330074854195118\n",
      "For the level Strain the F1 score is: 0.0011864355765283108\n",
      "\n",
      "--- Multi level evaluation test_spec ---\n",
      "\n",
      "--- Calculating Accuracy ---\n",
      "For the level Family the accu score is: 0.1920693963766098\n",
      "For the level Genus the accu score is: 0.048327136784791946\n",
      "For the level Species the accu score is: 0.0028913673013448715\n",
      "For the level Strain the accu score is: 0.0028913673013448715\n",
      "\n",
      "--- Calculating F1 scores ---\n",
      "For the level Family the F1 score is: 0.027058323845267296\n",
      "For the level Genus the F1 score is: 0.010356971994042397\n",
      "For the level Species the F1 score is: 0.0008160818833857775\n",
      "For the level Strain the F1 score is: 0.0007695098756812513\n",
      "\n",
      "--- Multi level evaluation test_strain ---\n",
      "\n",
      "--- Calculating Accuracy ---\n",
      "For the level Family the accu score is: 0.2872670888900757\n",
      "For the level Genus the accu score is: 0.06055900454521179\n",
      "For the level Species the accu score is: 0.001552795059978962\n",
      "For the level Strain the accu score is: 0.0\n",
      "\n",
      "--- Calculating F1 scores ---\n",
      "For the level Family the F1 score is: 0.04548368230462074\n",
      "For the level Genus the F1 score is: 0.014756916090846062\n",
      "For the level Species the F1 score is: 0.00028288541943766177\n",
      "For the level Strain the F1 score is: 0.0\n"
     ]
    }
   ],
   "source": [
    "from maldi_zsl_edit.utils import ZSL_levels_metrics\n",
    "data_path = \"Data/zsl_SINAwasabi.h5t\"\n",
    "levels = [\"Family\", \"Genus\", \"Species\", \"Strain\"]\n",
    "accug, f1g, gen, unacc, snacc, hmean, ev_species, labels = ZSL_levels_metrics(data_path,model,levels,\"Test\",split_index=2,general=False) #Consider the split and the new labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
