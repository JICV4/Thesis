{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lightning.pytorch import Trainer #https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from maldi_zsl_edit.data import MALDITOFDataModule\n",
    "from maldi_zsl_edit.models import ZSLClassifier\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What to tune\n",
    "batch_size = 16, 32 ,64\n",
    "dim_emb = 512,788,1014\n",
    "lr=1e-4,1e-6\n",
    "dropout = 0.2,0.5\n",
    "k_n = 3,5,7\n",
    "c_n = 0,64,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data set\n",
    "dm = MALDITOFDataModule( #Personalized lightning data modules\n",
    "    \"../Data/zsl_binned_new.h5t\", #The old has problems on split\n",
    "    zsl_mode = True, # False: multi-class CLF, True: ZSL\n",
    "    split_index = 0, # independent train-val-test split numbered 0-9\n",
    "    batch_size = 32, # important hyperparameter\n",
    "    n_workers = 2, # you can leave this always if you are not CPU limited\n",
    "    in_memory = True, # you can leave this always if memory is no problem\n",
    "    )\n",
    "\n",
    "dm.setup(None)\n",
    "#batch = next(iter(dm.train_dataloader()))\n",
    "#batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now there should be a batch instance [\"seq_ohe]\", replace the batch[\"seq\"] with it in the models file\n",
    "n_species = 160 #batch['strain'].shape[0] #Number the seq considered for the train, #The batch should be 623 (463 of training and 160 of val, the rest 165 are on test)\n",
    "t_species = 463\n",
    "#To add the correct number of n_species you need to correct the sequences seen per batch\n",
    "dim_emb = 1024\n",
    "model = ZSLClassifier(\n",
    "    mlp_kwargs = { #specify the parameters to buld the MLP ()\n",
    "        'n_inputs' : 6000, #Bins of the spectra\n",
    "        'emb_dim' : dim_emb, #This is the output of the branch\n",
    "        'layer_dims': [256, 128],\n",
    "        'layer_or_batchnorm' : \"layer\",\n",
    "        'dropout' : 0.2,\n",
    "    },\n",
    "    cnn_kwargs= { #specify the parameters to buld the CNN ()\n",
    "        'vocab_size' : 6, #Number of words, in this case is 5 as (A,T,C,G,-)\n",
    "        'emb_dim' : dim_emb, #This is the output of the branch\n",
    "        'conv_sizes' : [64, 128], #[32, 64, 128] Out chanels of the convolutions #On the nlp mode the first is an embeding dimension\n",
    "        'hidden_sizes' : [0], #MLP: [512, 256]. If [0] then goes directly from conv to embeding layer\n",
    "        #IMPORTANT: The models for classification have first the convolution and then a MLP, consider to also add the MLP in the model\n",
    "        #Note: The first hidden state is the embedding dim of the seq language processing and need to be optimized\n",
    "        #Note2: The last is the embedding dim for the shared space and score function\n",
    "        'blocks_per_stage' : 2, #How many residual blocks are applied before the pooling\n",
    "        'kernel_size' : 7,\n",
    "        #Stride?\n",
    "        #Max average or non?\n",
    "        'dropout' : 0.2,\n",
    "        'nlp' : False #Move directly to the branch\n",
    "    },\n",
    "    n_classes = n_species,\n",
    "    t_classes = t_species,\n",
    "    lr=1e-4, # important to tune\n",
    "    weight_decay=0, # this you can keep constant\n",
    "    lr_decay_factor=1.00, # this you can keep constant\n",
    "    warmup_steps=250, # this you can keep constant\n",
    "    #nlp = False #Try\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/Thesis/lib/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#Save and monitor training with tensor board\n",
    "from datetime import datetime\n",
    "timenow = datetime.now()\n",
    "strtime = timenow.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "val_ckpt = ModelCheckpoint(monitor=\"val_acc\", mode=\"max\")\n",
    "callbacks = [val_ckpt, EarlyStopping(monitor=\"val_acc\", patience=10, mode=\"max\")]\n",
    "logger = TensorBoardLogger(\"../logs_folder\", name=\"zsl_train_try2\", version=strtime) # Ctrl+Shift+P # Main folder where the training is saved and the name for the training\n",
    "\n",
    "#Training specification\n",
    "trainer = Trainer(\n",
    "    max_epochs = 100, \n",
    "    accelerator='gpu', \n",
    "    strategy='auto',\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    devices=[0]) #You can define epochs and training devices (look on documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/Thesis/lib/python3.11/site-packages/torch/cuda/__init__.py:190: UserWarning: \n",
      "    Found GPU1 NVIDIA Tesla K40c which is of cuda capability 3.5.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is 3.7.\n",
      "    \n",
      "  warnings.warn(\n",
      "2024-07-19 06:29:25.362198: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-19 06:29:26.268738: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name              | Type               | Params\n",
      "---------------------------------------------------------\n",
      "0 | spectrum_embedder | MLPEmbedding       | 1.9 M \n",
      "1 | seq_embedder      | CNNEmbedding       | 372 K \n",
      "2 | accuracy          | MulticlassAccuracy | 0     \n",
      "3 | accuracy2         | MulticlassAccuracy | 0     \n",
      "4 | top5_accuracy     | MulticlassAccuracy | 0     \n",
      "---------------------------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "9.127     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/Thesis/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\n",
      "Epoch 0 - Train loss: NA, Train accu: 0.0\n",
      "Epoch 0 - Val loss: 6.65458869934082, Val accu: 0.0\n",
      "\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/Thesis/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 527/527 [05:18<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 0 - Train loss: 8.811540603637695, Train accu: 0.0017789374105632305\n",
      "Epoch 0 - Val loss: 5.0762457847595215, Val accu: 0.012768817134201527\n",
      "\n",
      "Epoch 1: 100%|██████████| 527/527 [05:19<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 1 - Train loss: 6.4172563552856445, Train accu: 0.002964895684272051\n",
      "Epoch 1 - Val loss: 5.082064151763916, Val accu: 0.009072580374777317\n",
      "\n",
      "Epoch 2: 100%|██████████| 527/527 [05:19<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 2 - Train loss: 6.325634002685547, Train accu: 0.0016603415133431554\n",
      "Epoch 2 - Val loss: 5.075387001037598, Val accu: 0.010080644860863686\n",
      "\n",
      "Epoch 3: 100%|██████████| 527/527 [05:19<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 3 - Train loss: 6.276715278625488, Train accu: 0.0024312143214046955\n",
      "Epoch 3 - Val loss: 5.0764851570129395, Val accu: 0.005376344081014395\n",
      "\n",
      "Epoch 4: 100%|██████████| 527/527 [05:19<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 4 - Train loss: 6.241939544677734, Train accu: 0.0027277038898319006\n",
      "Epoch 4 - Val loss: 5.0743489265441895, Val accu: 0.0016801075544208288\n",
      "\n",
      "Epoch 5: 100%|██████████| 527/527 [05:19<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 5 - Train loss: 6.221640586853027, Train accu: 0.0021347247529774904\n",
      "Epoch 5 - Val loss: 5.072673320770264, Val accu: 0.005376344081014395\n",
      "\n",
      "Epoch 6: 100%|██████████| 527/527 [05:19<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 6 - Train loss: 6.2075676918029785, Train accu: 0.0018382353009656072\n",
      "Epoch 6 - Val loss: 5.080257415771484, Val accu: 0.005376344081014395\n",
      "\n",
      "Epoch 7: 100%|██████████| 527/527 [05:20<00:00,  1.64it/s, v_num=9-25]\n",
      "Epoch 7 - Train loss: 6.194944858551025, Train accu: 0.0016603415133431554\n",
      "Epoch 7 - Val loss: 5.072598457336426, Val accu: 0.009576613083481789\n",
      "\n",
      "Epoch 8: 100%|██████████| 527/527 [05:19<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 8 - Train loss: 6.187426567077637, Train accu: 0.0013045540545135736\n",
      "Epoch 8 - Val loss: 5.0799384117126465, Val accu: 0.005376344081014395\n",
      "\n",
      "Epoch 9: 100%|██████████| 527/527 [05:19<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 9 - Train loss: 6.181343078613281, Train accu: 0.0023719165474176407\n",
      "Epoch 9 - Val loss: 5.076725006103516, Val accu: 0.009576613083481789\n",
      "\n",
      "Epoch 10: 100%|██████████| 527/527 [05:19<00:00,  1.65it/s, v_num=9-25]\n",
      "Epoch 10 - Train loss: 6.1689558029174805, Train accu: 0.0024312143214046955\n",
      "Epoch 10 - Val loss: 5.056715488433838, Val accu: 0.00924059096723795\n",
      "\n",
      "Epoch 10: 100%|██████████| 527/527 [05:36<00:00,  1.57it/s, v_num=9-25]\n"
     ]
    }
   ],
   "source": [
    "#Pre-save the model\n",
    "#sure = True\n",
    "#if sure:\n",
    "#    torch.save(model, f'../SavedModels/ZSLmodel{strtime}.pth')\n",
    "#    print(f\"Saved as ZSLmodel{strtime}.pth\")\n",
    "#model.load_from_checkpoint('../logs_folder/zsl_train_try2/2024-07-16_08-12-50/checkpoints/epoch=25-step=27404.ckpt') #load model from if needed\n",
    "\n",
    "#Start training\n",
    "trainer.fit(model, dm.train_dataloader(), dm.val_dataloader()) #Important: normally you can use only dm, but here we specify as the dim of a are different for train and val \n",
    "#Note: The model object specify what is considered an input values and what is considered an input/output value during the training on the training step method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as ZSLmodel2024-07-19_06-29-25.pth\n"
     ]
    }
   ],
   "source": [
    "#timenow = datetime.now()\n",
    "#traintime = timenow.strftime(\"%Y-%m-%d_%H-%M-%S\") - strtime\n",
    "#print(f\"The model lasted {traintime} to train\")\n",
    "\n",
    "#Save the model also at the end of the training\n",
    "sure = True\n",
    "if sure:\n",
    "    torch.save(model, f'../SavedModels/ZSLmodel{strtime}.pth')\n",
    "    print(f\"Saved as ZSLmodel{strtime}.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "sure = False\n",
    "if sure:\n",
    "    model = torch.load('../SavedModels/ZSLmodel2024-07-13_02-56-19.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6000])\n",
      "torch.Size([160, 6, 2236])\n"
     ]
    }
   ],
   "source": [
    "minibatch = next(iter(dm.val_dataloader()))\n",
    "print(minibatch[\"intensity\"].shape)\n",
    "print(minibatch[\"seq_ohe\"].shape) #The batch should be 623 (463 of training and 160 of val, the rest 165 are on test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <HDF5 group \"/0\" (11 members)>\n",
      "0/intensity <HDF5 dataset \"intensity\": shape (29105, 6000), type \"<f4\">\n",
      "0/split_0 <HDF5 dataset \"split_0\": shape (29105,), type \"|S11\">\n",
      "0/split_1 <HDF5 dataset \"split_1\": shape (29105,), type \"|S11\">\n",
      "0/split_2 <HDF5 dataset \"split_2\": shape (29105,), type \"|S11\">\n",
      "0/split_3 <HDF5 dataset \"split_3\": shape (29105,), type \"|S11\">\n",
      "0/split_4 <HDF5 dataset \"split_4\": shape (29105,), type \"|S11\">\n",
      "0/split_5 <HDF5 dataset \"split_5\": shape (29105,), type \"|S11\">\n",
      "0/split_6 <HDF5 dataset \"split_6\": shape (29105,), type \"|S11\">\n",
      "0/split_7 <HDF5 dataset \"split_7\": shape (29105,), type \"|S11\">\n",
      "0/split_8 <HDF5 dataset \"split_8\": shape (29105,), type \"|S11\">\n",
      "0/split_9 <HDF5 dataset \"split_9\": shape (29105,), type \"|S11\">\n",
      "1 <HDF5 group \"/1\" (4 members)>\n",
      "1/strain_names <HDF5 dataset \"strain_names\": shape (788,), type \"|S124\">\n",
      "1/strain_seq <HDF5 dataset \"strain_seq\": shape (788,), type \"|S1676\">\n",
      "1/strain_seq_aligned <HDF5 dataset \"strain_seq_aligned\": shape (788, 2236), type \"|i1\">\n",
      "1/strain_seq_aligned_ohe <HDF5 dataset \"strain_seq_aligned_ohe\": shape (788, 6, 2236), type \"|b1\">\n",
      "central <HDF5 dataset \"central\": shape (29105, 788), type \"|b1\">\n",
      "unstructured <HDF5 group \"/unstructured\" (1 members)>\n",
      "unstructured/mz <HDF5 dataset \"mz\": shape (6000,), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "#Info of the data set\n",
    "h5spectra = h5py.File(\"../Data/zsl_binned_new.h5t\", \"r\") # The old version has problems on the split\n",
    "h5spectra.visititems(print)\n",
    "#There are train: 463, val :160 and test: 165 \n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the predictions to look their individual accuracies\n",
    "ev_species = {}\n",
    "ev_species[b'train'] = []\n",
    "ev_species[b'val_geni'] = []\n",
    "ev_species[b'val_spec'] = []\n",
    "ev_species[b'val_strain'] = []\n",
    "study = [b'train',b'val_geni',b'val_spec',b'val_strain']\n",
    "i = 0\n",
    "for label in h5spectra[\"0\"][\"split_0\"]:\n",
    "    if label in study:\n",
    "        a = h5spectra[\"central\"][i]\n",
    "        b = np.where(a == True)[0][0]\n",
    "        ev_species[label].append(b)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5941, 160])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5757, -0.1364, -0.5885,  ..., -0.7908, -0.4338, -0.3347],\n",
       "        [ 3.7039,  4.4235,  3.1040,  ...,  3.2766,  3.4193,  3.7365],\n",
       "        [-2.5605, -2.2706, -2.8003,  ..., -2.6501, -2.4468, -2.4962],\n",
       "        ...,\n",
       "        [12.4245, 11.9488, 11.1080,  ..., 11.5319, 11.6720, 12.1082],\n",
       "        [-0.4275, -0.7524, -1.0025,  ..., -1.0437, -0.7795, -0.7447],\n",
       "        [ 1.9765,  1.3395,  1.0238,  ...,  0.8340,  1.4872,  1.7841]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manual calculation of the predictions\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "y_pred = torch.empty((0,160)) #the second is the number of species #Change to 788 or 463 for val vs train\n",
    "y_real= []\n",
    "with torch.no_grad():\n",
    "    for minibatch in iter(dm.val_dataloader()): #On the split said if train, val, etc, \n",
    "        y_hat = model(minibatch)\n",
    "        y_pred = torch.cat((y_pred,y_hat),dim=0)\n",
    "        y_real+= list(minibatch['strain'])\n",
    "print(y_pred.shape) #(batch size, total possible species)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels for Multilevel evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ind = torch.argmax(y_pred, axis=1)\n",
    "real_ind = y_real\n",
    "levels = [\"Family\", \"Genus\", \"Species\", \"Strain\"]\n",
    "granularity_lvl = len(levels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filos = minibatch[\"seq_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the multilevel predictions, consider how the data is encoded (genus, species, strain)\n",
    "ml_real = []\n",
    "ml_pred = []\n",
    "for i in range(len(y_real)):\n",
    "  #for real:\n",
    "  s_real = filos[real_ind[i]].split(\";\")\n",
    "  ml_real.append(s_real)\n",
    "  #for pred:\n",
    "  s_pred = filos[pred_ind[i]].split(\";\")\n",
    "  ml_pred.append(s_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get them on the right format\n",
    "import numpy as np\n",
    "ml_real = np.array(ml_real).T\n",
    "ml_pred = np.array(ml_pred).T\n",
    "#List for better iteratation\n",
    "ml_reals = ml_real.tolist()\n",
    "ml_preds = ml_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the possible multilevel labels\n",
    "ml_level = []\n",
    "for i in range(len(filos)):\n",
    "  s_level = filos[i].split(\";\")\n",
    "  ml_level.append(s_level)\n",
    "ml_level = np.array(ml_level).T\n",
    "ml_levels = ml_level.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Family there are 33 different labels\n",
      "For Genus there are 52 different labels\n",
      "For Species there are 152 different labels\n",
      "For Strain there are 160 different labels\n"
     ]
    }
   ],
   "source": [
    "#Total number of labels\n",
    "for i in range(granularity_lvl):\n",
    "    n = len(list(set(ml_levels[i])))\n",
    "    print(f\"For {levels[i]} there are {n} different labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score #There is also a torch version, consider it\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "#Create a accuracy evaluator\n",
    "def accu_score(y_true, y_pred, level_lab):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true_encoded = label_encoder.fit_transform(level_lab)\n",
    "    y_true_encoded = label_encoder.transform(y_true)\n",
    "    y_pred_encoded = label_encoder.transform(y_pred)\n",
    "\n",
    "    #Using sklearn\n",
    "    #accu = accuracy_score(y_true_encoded, y_pred_encoded, normalize=True) #The normalize True = number of correct predictions, False = fraction of correct predictions\n",
    "    \n",
    "    #Using torch\n",
    "    accu = Accuracy(task=\"multiclass\", num_classes=len(set(level_lab))) \n",
    "    accu = accu(torch.tensor(y_pred_encoded), torch.tensor(y_true_encoded))\n",
    "    \n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run accu for each level of complexity\n",
    "accu_levels = []\n",
    "for level in range(granularity_lvl ):\n",
    "  accu_levels.append(accu_score(ml_reals[level], ml_preds[level], ml_levels[level]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the level Family the accu score is: 0.09089379012584686\n",
      "For the level Genus the accu score is: 0.05201144516468048\n",
      "For the level Species the accu score is: 0.005722942296415567\n",
      "For the level Strain the accu score is: 0.0055546206422150135\n"
     ]
    }
   ],
   "source": [
    "# see the results\n",
    "for i in range(granularity_lvl ):\n",
    "  print(f\"For the level {levels[i]} the accu score is: {accu_levels[i]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "#Create an F1 evaluator\n",
    "def f1_macro_score(y_true, y_pred, level_lab): #micro average is basically accuracy\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true_encoded = label_encoder.fit_transform(level_lab)\n",
    "    y_true_encoded = label_encoder.transform(y_true)\n",
    "    y_pred_encoded = label_encoder.transform(y_pred)\n",
    "\n",
    "    #Using sklearn\n",
    "    #f1_scores = f1_score(y_true_encoded, y_pred_encoded, average=None)\n",
    "    #macro_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    #Using torch\n",
    "    macro_f1 = F1Score(task=\"multiclass\", num_classes=len(set(level_lab)), average='macro') \n",
    "    macro_f1 = macro_f1(torch.tensor(y_pred_encoded), torch.tensor(y_true_encoded))\n",
    "\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run f1_macro_score for each level of complexity\n",
    "F1_levels = []\n",
    "for level in range(granularity_lvl ):\n",
    "  F1_levels.append(f1_macro_score(ml_reals[level], ml_preds[level], ml_levels[level]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the level Family the F1 score is: 0.037777528166770935\n",
      "For the level Genus the F1 score is: 0.02623894438147545\n",
      "For the level Species the F1 score is: 0.006067595444619656\n",
      "For the level Strain the F1 score is: 0.005674286745488644\n"
     ]
    }
   ],
   "source": [
    "# see the results\n",
    "for i in range(granularity_lvl ):\n",
    "  print(f\"For the level {levels[i]} the F1 score is: {F1_levels[i]}\") #The predictions are no the same as the output, maybe F1 is not used there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
