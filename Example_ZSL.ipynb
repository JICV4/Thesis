{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lightning.pytorch import Trainer #https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from maldi_zsl_edit.data import MALDITOFDataModule\n",
    "from maldi_zsl_edit.models import ZSLClassifier\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What to tune\n",
    "batch_size = 16\n",
    "dim_emb = 788\n",
    "lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data set\n",
    "dm = MALDITOFDataModule( #Personalized lightning data modules\n",
    "    \"../Data/zsl_binned_new.h5t\", #The old has problems on split\n",
    "    zsl_mode = True, # False: multi-class CLF, True: ZSL\n",
    "    split_index = 0, # independent train-val-test split numbered 0-9\n",
    "    batch_size = 16, # important hyperparameter\n",
    "    n_workers = 2, # you can leave this always if you are not CPU limited\n",
    "    in_memory = True, # you can leave this always if memory is no problem\n",
    "    )\n",
    "\n",
    "dm.setup(None)\n",
    "#batch = next(iter(dm.train_dataloader()))\n",
    "#batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now there should be a batch instance [\"seq_ohe]\", replace the batch[\"seq\"] with it in the models file\n",
    "n_species = 160 #batch['strain'].shape[0] #Number the seq considered for the train, #The batch should be 623 (463 of training and 160 of val, the rest 165 are on test)\n",
    "#To add the correct number of n_species you need to correct the sequences seen per batch\n",
    "dim_emb = 788\n",
    "model = ZSLClassifier(\n",
    "    mlp_kwargs = { #specify the parameters to buld the MLP ()\n",
    "        'n_inputs' : 6000, #Bins of the spectra\n",
    "        'emb_dim' : dim_emb, #This is the output of the branch\n",
    "        'layer_dims': [512, 256],\n",
    "        'layer_or_batchnorm' : \"layer\",\n",
    "        'dropout' : 0.2,\n",
    "    },\n",
    "    cnn_kwargs= { #specify the parameters to buld the CNN ()\n",
    "        'vocab_size' : 6, #Number of words, in this case is 5 as (A,T,C,G,-)\n",
    "        'emb_dim' : dim_emb, #This is the output of the branch\n",
    "        'conv_sizes' : [64, 128], #[32, 64, 128] Out chanels of the convolutions #On the nlp mode the first is an embeding dimension\n",
    "        'hidden_sizes' : False, #MLP: [512, 256]. If false then goes directly from conv to embeding layer\n",
    "        #IMPORTANT: The models for classification have first the convolution and then a MLP, consider to also add the MLP in the model\n",
    "        #Note: The first hidden state is the embedding dim of the seq language processing and need to be optimized\n",
    "        #Note2: The last is the embedding dim for the shared space and score function\n",
    "        'blocks_per_stage' : 2, #How many residual blocks are applied before the pooling\n",
    "        'kernel_size' : 7,\n",
    "        #Stride?\n",
    "        #Max average or non?\n",
    "        'dropout' : 0.2,\n",
    "        'nlp' : False #Move directly to the branch\n",
    "    },\n",
    "    n_classes = n_species,\n",
    "    lr=1e-4, # important to tune\n",
    "    weight_decay=0, # this you can keep constant\n",
    "    lr_decay_factor=1.00, # this you can keep constant\n",
    "    warmup_steps=250, # this you can keep constant\n",
    "    #nlp = False #Try\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#Save and monitor training with tensor board\n",
    "from datetime import datetime\n",
    "timenow = datetime.now()\n",
    "strtime = timenow.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "val_ckpt = ModelCheckpoint(monitor=\"val_acc\", mode=\"max\")\n",
    "callbacks = [val_ckpt, EarlyStopping(monitor=\"val_acc\", patience=10, mode=\"max\")]\n",
    "logger = TensorBoardLogger(\"../logs_folder\", name=\"zsl_train_try2\", version=strtime) # Ctrl+Shift+P # Main folder where the training is saved and the name for the training\n",
    "\n",
    "#Training specification\n",
    "trainer = Trainer(\n",
    "    max_epochs = 100, \n",
    "    accelerator='gpu', \n",
    "    strategy='auto',\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    devices=[0]) #You can define epochs and training devices (look on documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Start training ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 22:48:45.022521: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 22:48:45.943071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name              | Type               | Params\n",
      "---------------------------------------------------------\n",
      "0 | spectrum_embedder | MLPEmbedding       | 3.6 M \n",
      "1 | seq_embedder      | CNNEmbedding       | 372 K \n",
      "2 | accuracy          | MulticlassAccuracy | 0     \n",
      "3 | top5_accuracy     | MulticlassAccuracy | 0     \n",
      "---------------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.935    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/Thesis/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/Thesis/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1054/1054 [11:17<00:00,  1.56it/s, v_num=70]\n"
     ]
    }
   ],
   "source": [
    "#Start training\n",
    "print(\"\\n--- Start training ---\\n\")\n",
    "trainer.fit(model, dm.train_dataloader(), dm.val_dataloader()) #Important: normally you can use only dm, but here we specify as the dim of a are different for train and val \n",
    "#Note: The model object specify what is considered an input values and what is considered an input/output value during the training on the training step method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as ZSLmodel2024-07-16_00-53-07.pth\n"
     ]
    }
   ],
   "source": [
    "#Save the model\n",
    "sure = True\n",
    "if sure:\n",
    "    torch.save(model, f'../SavedModels/ZSLmodel{strtime}.pth')\n",
    "    print(f\"Saved as ZSLmodel{strtime}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timenow = datetime.now()\n",
    "traintime = timenow.strftime(\"%Y-%m-%d_%H-%M-%S\") - strtime\n",
    "print(f\"The model lasted {traintime} to train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "sure = False\n",
    "if sure:\n",
    "    model = torch.load('../SavedModels/ZSLmodel2024-07-13_02-56-19.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6000])\n",
      "torch.Size([160, 6, 2236])\n"
     ]
    }
   ],
   "source": [
    "minibatch = next(iter(dm.val_dataloader()))\n",
    "print(minibatch[\"intensity\"].shape)\n",
    "print(minibatch[\"seq_ohe\"].shape) #The batch should be 623 (463 of training and 160 of val, the rest 165 are on test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <HDF5 group \"/0\" (11 members)>\n",
      "0/intensity <HDF5 dataset \"intensity\": shape (29105, 6000), type \"<f4\">\n",
      "0/split_0 <HDF5 dataset \"split_0\": shape (29105,), type \"|S11\">\n",
      "0/split_1 <HDF5 dataset \"split_1\": shape (29105,), type \"|S11\">\n",
      "0/split_2 <HDF5 dataset \"split_2\": shape (29105,), type \"|S11\">\n",
      "0/split_3 <HDF5 dataset \"split_3\": shape (29105,), type \"|S11\">\n",
      "0/split_4 <HDF5 dataset \"split_4\": shape (29105,), type \"|S11\">\n",
      "0/split_5 <HDF5 dataset \"split_5\": shape (29105,), type \"|S11\">\n",
      "0/split_6 <HDF5 dataset \"split_6\": shape (29105,), type \"|S11\">\n",
      "0/split_7 <HDF5 dataset \"split_7\": shape (29105,), type \"|S11\">\n",
      "0/split_8 <HDF5 dataset \"split_8\": shape (29105,), type \"|S11\">\n",
      "0/split_9 <HDF5 dataset \"split_9\": shape (29105,), type \"|S11\">\n",
      "1 <HDF5 group \"/1\" (4 members)>\n",
      "1/strain_names <HDF5 dataset \"strain_names\": shape (788,), type \"|S124\">\n",
      "1/strain_seq <HDF5 dataset \"strain_seq\": shape (788,), type \"|S1676\">\n",
      "1/strain_seq_aligned <HDF5 dataset \"strain_seq_aligned\": shape (788, 2236), type \"|i1\">\n",
      "1/strain_seq_aligned_ohe <HDF5 dataset \"strain_seq_aligned_ohe\": shape (788, 6, 2236), type \"|b1\">\n",
      "central <HDF5 dataset \"central\": shape (29105, 788), type \"|b1\">\n",
      "unstructured <HDF5 group \"/unstructured\" (1 members)>\n",
      "unstructured/mz <HDF5 dataset \"mz\": shape (6000,), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "#Info of the data set\n",
    "h5spectra = h5py.File(\"../Data/zsl_binned_new.h5t\", \"r\") # The old version has problems on the split\n",
    "h5spectra.visititems(print)\n",
    "#There are train: 463, val :160 and test: 165 \n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the predictions to look their individual accuracies\n",
    "ev_species = {}\n",
    "ev_species[b'train'] = []\n",
    "ev_species[b'val_geni'] = []\n",
    "ev_species[b'val_spec'] = []\n",
    "ev_species[b'val_strain'] = []\n",
    "study = [b'train',b'val_geni',b'val_spec',b'val_strain']\n",
    "i = 0\n",
    "for label in h5spectra[\"0\"][\"split_0\"]:\n",
    "    if label in study:\n",
    "        a = h5spectra[\"central\"][i]\n",
    "        b = np.where(a == True)[0][0]\n",
    "        ev_species[label].append(b)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5941, 160])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.5486,  5.8773,  5.6896,  ...,  5.5123,  5.0793,  5.6174],\n",
       "        [ 9.3029,  9.5434,  9.3714,  ...,  9.4253,  9.4181,  9.4378],\n",
       "        [11.5071, 11.7894, 11.6981,  ..., 11.8055, 11.7044, 11.8618],\n",
       "        ...,\n",
       "        [ 5.0884,  4.5958,  4.6023,  ...,  4.6073,  4.7199,  4.3283],\n",
       "        [-0.1079, -0.7426, -0.2282,  ..., -0.9831, -0.7771, -1.4235],\n",
       "        [ 9.8488,  9.6293,  9.4613,  ...,  9.4404,  9.3853,  9.1756]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manual calculation of the predictions\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "y_pred = torch.empty((0,160)) #the second is the number of species #Change to 788 or 463 for val vs train\n",
    "y_real= []\n",
    "with torch.no_grad():\n",
    "    for minibatch in iter(dm.val_dataloader()): #On the split said if train, val, etc, \n",
    "        y_hat = model(minibatch)\n",
    "        y_pred = torch.cat((y_pred,y_hat),dim=0)\n",
    "        y_real+= list(minibatch['strain'])\n",
    "print(y_pred.shape) #(batch size, total possible species)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels for Multilevel evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ind = torch.argmax(y_pred, axis=1)\n",
    "real_ind = y_real\n",
    "levels = [\"Family\", \"Genus\", \"Species\", \"Strain\"]\n",
    "granularity_lvl = len(levels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filos = minibatch[\"seq_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the multilevel predictions, consider how the data is encoded (genus, species, strain)\n",
    "ml_real = []\n",
    "ml_pred = []\n",
    "for i in range(len(y_real)):\n",
    "  #for real:\n",
    "  s_real = filos[real_ind[i]].split(\";\")\n",
    "  ml_real.append(s_real)\n",
    "  #for pred:\n",
    "  s_pred = filos[pred_ind[i]].split(\";\")\n",
    "  ml_pred.append(s_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get them on the right format\n",
    "import numpy as np\n",
    "ml_real = np.array(ml_real).T\n",
    "ml_pred = np.array(ml_pred).T\n",
    "#List for better iteratation\n",
    "ml_reals = ml_real.tolist()\n",
    "ml_preds = ml_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the possible multilevel labels\n",
    "ml_level = []\n",
    "for i in range(len(filos)):\n",
    "  s_level = filos[i].split(\";\")\n",
    "  ml_level.append(s_level)\n",
    "ml_level = np.array(ml_level).T\n",
    "ml_levels = ml_level.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Family there are 33 different labels\n",
      "For Genus there are 52 different labels\n",
      "For Species there are 152 different labels\n",
      "For Strain there are 160 different labels\n"
     ]
    }
   ],
   "source": [
    "#Total number of labels\n",
    "for i in range(granularity_lvl):\n",
    "    n = len(list(set(ml_levels[i])))\n",
    "    print(f\"For {levels[i]} there are {n} different labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score #There is also a torch version, consider it\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "#Create a accuracy evaluator\n",
    "def accu_score(y_true, y_pred, level_lab):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true_encoded = label_encoder.fit_transform(level_lab)\n",
    "    y_true_encoded = label_encoder.transform(y_true)\n",
    "    y_pred_encoded = label_encoder.transform(y_pred)\n",
    "\n",
    "    #Using sklearn\n",
    "    #accu = accuracy_score(y_true_encoded, y_pred_encoded, normalize=True) #The normalize True = number of correct predictions, False = fraction of correct predictions\n",
    "    \n",
    "    #Using torch\n",
    "    accu = Accuracy(task=\"multiclass\", num_classes=len(set(level_lab))) \n",
    "    accu = accu(torch.tensor(y_pred_encoded), torch.tensor(y_true_encoded))\n",
    "    \n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run accu for each level of complexity\n",
    "accu_levels = []\n",
    "for level in range(granularity_lvl ):\n",
    "  accu_levels.append(accu_score(ml_reals[level], ml_preds[level], ml_levels[level]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the level Family the accu score is: 0.08432924002408981\n",
      "For the level Genus the accu score is: 0.0441003181040287\n",
      "For the level Species the accu score is: 0.007742804009467363\n",
      "For the level Strain the accu score is: 0.005891263950616121\n"
     ]
    }
   ],
   "source": [
    "# see the results\n",
    "for i in range(granularity_lvl ):\n",
    "  print(f\"For the level {levels[i]} the accu score is: {accu_levels[i]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "#Create an F1 evaluator\n",
    "def f1_macro_score(y_true, y_pred, level_lab): #micro average is basically accuracy\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true_encoded = label_encoder.fit_transform(level_lab)\n",
    "    y_true_encoded = label_encoder.transform(y_true)\n",
    "    y_pred_encoded = label_encoder.transform(y_pred)\n",
    "\n",
    "    #Using sklearn\n",
    "    #f1_scores = f1_score(y_true_encoded, y_pred_encoded, average=None)\n",
    "    #macro_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    #Using torch\n",
    "    macro_f1 = F1Score(task=\"multiclass\", num_classes=len(set(level_lab)), average='macro') \n",
    "    macro_f1 = macro_f1(torch.tensor(y_pred_encoded), torch.tensor(y_true_encoded))\n",
    "\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run f1_macro_score for each level of complexity\n",
    "F1_levels = []\n",
    "for level in range(granularity_lvl ):\n",
    "  F1_levels.append(f1_macro_score(ml_reals[level], ml_preds[level], ml_levels[level]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the level Family the F1 score is: 0.027643362060189247\n",
      "For the level Genus the F1 score is: 0.018193526193499565\n",
      "For the level Species the F1 score is: 0.0066812289878726006\n",
      "For the level Strain the F1 score is: 0.005795252043753862\n"
     ]
    }
   ],
   "source": [
    "# see the results\n",
    "for i in range(granularity_lvl ):\n",
    "  print(f\"For the level {levels[i]} the F1 score is: {F1_levels[i]}\") #The predictions are no the same as the output, maybe F1 is not used there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
